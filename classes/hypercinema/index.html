<!DOCTYPE html>
<html lang="en">
<head>
    <title>Hypercinema • Nasif's ITP Blog</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.7.3/p5.min.js" defer></script>
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.7.3/addons/p5.dom.min.js"></script> -->
    <!-- <script type="text/javascript" src="https://rawgit.com/patriciogonzalezvivo/glslCanvas/master/dist/GlslCanvas.js"></script> -->
    <link rel="stylesheet" type="text/css" href="../../style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
    <link href="https://fonts.googleapis.com/css2?family=Recursive:wght,CRSV,MONO@300..1000,0,0..1&family=Noto+Color+Emoji&display=block" rel="stylesheet"> 
    <meta name="description" content="Nasif's experience at the ITP Hypercinema course.">
    <meta name=”robots” content=”index, follow”>
    <link rel="icon" type="image/png" href="../../favicon.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8" />
</head>    
<body>
    <main class="page-container course-container">
        <hgroup>
            <p class="course-meta">Fall 2024 • Gabriel Barcia-Colombo</p>
            <h1 class="project-title">Hypercinema</h1>
        </hgroup>
        <div class="text-content">
            <div class="blog-week">
                <h2 class="project-subtitle">Week 08: Synthetic Media</h2>
                <p>As an example of synthetic media, I looked into the work of artist Björn Karmann. Specifically his "Paragraphica" camera. This is a camera that doesn't take photos through a lens, but rather uses geolocation data taken when pressing the shutter to generate an image with a text-to-image ai model.</p>
                <div class="image-slide">
                    <figure>
                        <img loading="lazy" src="https://bjoernkarmann.dk/wp-content/uploads/2023/05/head_web.png" alt="">
                        <figcaption>The camera takes the shape of the star-nosed mole, which perceives the world through antennae instead of eyes.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://bjoernkarmann.dk/wp-content/uploads/2023/05/screen_web.png" alt="">
                        <figcaption>The knobs allow users to alter some parameters of the photo to be generated. Other parameters come directly from the date/time/location where the "photo" is being taken.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://bjoernkarmann.dk/wp-content/uploads/2023/05/Group-143-2.png" alt="">
                        <figcaption>Showing the location where the picture was taken, the prompt used, and the generated image.</figcaption>
                    </figure>
                </div>
                <p><strong>Why do you consider this synthetic media:</strong> This piece works with synthetic media because the images are not captured, rather generated using a text-to-image ai model.</p>
                <p><strong>What can you find about how this was made:</strong> To generate the images, this work uses the Stable Diffusion API. This model was trained on images from the LAION-5B dataset, which in turn gets images by crawling websites and storing the image together with the alt-text value. That is how it manages to get descriptive text with each image, because the alt-text value is written for the visually impaired to understand what the image portrays.</p>
                <p><strong>What are the ethical ramifications of this specific example:</strong> I believe there are not any particular ethical issues from this particular piece, apart from the ethical issues from the Stable Diffusion model and the lack of consent from the owners of the training images. With regards to what it communicates, it is interesting to think that this piece will get the closest picture to the actual location if images of said location exist online. Because <a href="https://en.wikipedia.org/wiki/Languages_used_on_the_Internet" target="_blank">the internet is ~50% in English</a>, it is not unrealistic to think that locations where English is not spoken (or where the internet is not very prevalent) will not be represented well in the images generated by this camera. In a way it is a window into the "eyes" of the web.</p>
            </div>
            <div class="blog-week">
                <h2 class="project-subtitle">Week 03</h2>
                <p>This week we focused on making a short stop-motion animation in the format of a gif. Working with Audrey, we decided we wanted to make the animation with our bodies instead of puppets or props.</p>
                <p>I remembered <a href="https://trafficcamphotobooth.com/" target="_blank" rel="noopener noreferrer">Morry Kolman's Traffic Cam Photo Booth</a> which shows a realtime feed of nyc traffic cameras to snap pictures from your phone. We then decided to make our stop motion using those cameras instead of our own.</p>
                <p>We switched to the <a href="https://webcams.nyctmc.org/map" target="_blank" rel="noopener noreferrer">Official NYC DOT website</a> since the interface was more comfortable to record. Then, we chose two cameras in different parts of Brooklyn, that had the same perspective:</p>
                <div class="image-slide">
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/two-locations.webp" alt="Screenshot of a website showing two photos side by side, each of a different city crosswalk. One reads '7 Ave @ Union St' and the other '3rd Ave @ Atlantic Ave'.">
                        <figcaption>The two locations selected on the nyc dot website.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/curious-cam.webp" alt="Photo of a city street, with a very low resolution and in black and white, except for some pixels with color.">
                        <figcaption>We were also very intrigued by this camera. It seemed to be more pixelated and with a sort of color isolation filter on. We were not sure if this was a malfunction or the intended image the camera should be producing.</figcaption>
                    </figure>
                </div>
                <p>We planned out a simple animation that would connect these two places as if they were side by side and then went to each place to record.</p>
                <div class="image-slide">
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/3rd-atlantic.webp" alt="Photo of a traffic camera on top of a traffic light.">
                        <figcaption>The first camera, at the intersection of 3rd av and Atlantic av.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/selfie-atlantic.webp" alt="Low resolution photo of a crosswalk.">
                        <figcaption>We took a selfie before getting to work.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/audrey-directing.webp" alt="Person sitting down with a laptop in a bus stop.">
                        <figcaption>Audrey directing at our first location.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/union-7av.webp" alt="Photo of a traffic camera on top of a traffic light.">
                        <figcaption>The second camera, at the intersection of 7th av and Union St.</figcaption>
                    </figure>
                </div>
                <p>Once we finished recording, we headed back to campus and edited the frames, aligning the two takes on top of the original interface from the nyc dot website, to make it look as if it was happening realtime:</p>
                <figure>
                    <img loading="lazy" src="https://assets.nasif.co/stopping-traffic.gif" alt="Animated gif showing one person passing an umbrella to another person across two separate frames.">
                </figure>
            </div>
            <div class="blog-week">
                <h2 class="project-subtitle">Week 02</h2>
                <p>Our 2nd week assignment consisted in making a physical installation that mimics a particular sound of our choosing. We started with a trip to the hardware store, testing the sounds of some objects.</p>
                <div class="image-slide">
                    <figure>
                        <video controls src="https://assets.nasif.co/initial-sound-idea.webm" alt="A finger brushing over a blue plastic dish sponge."></video>
                        <figcaption>We found this brushing sound, especially the clicking that occurs when the plastic strands get caught onto the skin and then let go, to be somewhat like a fireplace, with its crackling embers.</figcaption>
                    </figure>
                </div>
                <p>We then attempted to design and build a structure to reproduce this sound on its own.</p>
                <div class="image-slide">
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/designing-structure.webp" alt="Sketches on a piece of paper.">
                        <figcaption>We made some sketches and tested out a mount with a heavy-duty metal wire.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/testing-structure.webp" alt="Hands holding metal wire wrapped around a dish sponge.">
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/testing-mount.webp" alt="A small dc with an eraser stuck to its axis, and a small cork touching the eraser on one side and a blue plastic dish sponge on the other..">
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/low-torque.webp" alt="Small makeshift structure with a wooden base, a plastic dish spong facing upwards, an a motor held right over it with a metal wire. A cork hangs from the motor over the sponge.">
                        <figcaption>This first iteration of the machine made us realize that the DC motor didn't have enough torque to brush against the sponge.</figcaption>
                    </figure>
                </div>
                <p>For the second iteration, we changed the motor for another type of DC motor with a gearbox that increased its torque.</p>
                <div class="image-slide">
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/gearbox-motor.webp" alt="DC gearbox motor in the forefront of the image.">
                        <figcaption>This 4.5V gearbox motor would have a more suitable torque for this application.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/mounted-motor.webp" alt="Small structure with a wooden base, a plastic dish spong facing upwards, an a motor held right over it with a metal wire.">
                        <figcaption>We built the mount again with the metal wire.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/3d-measurements.webp" alt="Hand made sketch with scribbled measurements.">
                        <figcaption>To take advantage of the torque, we needed to have a very good mount for the cork onto the motor. So we took some measurments with a calliper.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/3d-model-mount.webp" alt="3D model.">
                        <figcaption>Made a 3D model based on the measurements.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/3d-printed-mount.webp" alt="Small plastic object in a T shape.">
                        <figcaption>3D print of the model in PLA plastic.</figcaption>
                    </figure>
                    <figure>
                        <img loading="lazy" src="https://assets.nasif.co/mount-iteration.webp" alt="Small structure with a wooden base, a plastic dish spong facing upwards, an a motor held right over it with a metal wire. A small plastic t-shaped object mounts a cork to the motor spindle, and hangs over the sponge.">
                        <figcaption>The second iteration of the machine.</figcaption>
                    </figure>
                </div>
                <p>This new iteration worked much better! However, due to the friction between the gears, the motor also made a much louder noise that obscured the sound we wanted to make.</p>
                <p>Therefore we made a recording and <strong>used the 30 band equalizer to amplify the frequencies of the sponge and muffle the frequencies of the gearbox</strong>, in order to get closer to the sound we wanted.</p>
                <div class="image-slide">
                    <figure>
                        <video loading="lazy" controls src="https://assets.nasif.co/machine-edited-sound.webm" alt="Small structure with a wooden base, a plastic dish spong facing upwards, an a motor held right over it with a metal wire. A small plastic t-shaped object mounts a cork to the motor spindle, and hangs over the sponge. The motor spins at varying speeds and the cork brushes over the sponge."></video>
                        <figcaption>Recording of the final machine. <strong>The audio was edited to amplify the desired frequencies</strong>.</figcaption>
                    </figure>
                </div>
            </div>
            <div class="blog-week">
                <h2 class="project-subtitle">Week 01</h2>
                <p>For the first week, our assignment consisted of recording a series of sounds that represented different concepts. Together with Jinnie Shim & Ray Wang, we went out on a scavenger hunt and recorded the following audios.</p>
                <div class="audio-gallery">
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/loneliness.mp3"></audio>
                        <figcaption><strong>Loneliness</strong>: The sound of people leaving the subway station, walking up the stairs in silence.</figcaption>
                    </figure>
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/happinness.mp3"></audio>
                        <figcaption><strong>Happiness</strong>: A friday afternoon at the playground on Abolitionist Place.</figcaption>
                    </figure>
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/cold.mp3"></audio>
                        <figcaption><strong>Cold</strong>: Refreshing crackling ice on a hot summer day.</figcaption>
                    </figure>
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/hum.mp3"></audio>
                        <figcaption><strong>Hum</strong>: The sound of a microwave running.</figcaption>
                    </figure>
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/metal.mp3"></audio>
                        <figcaption><strong>Metal</strong>: The mechanical sounds of a 370 Jay St. elevator door opening.</figcaption>
                    </figure>
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/ticking.mp3"></audio>
                        <figcaption><strong>Ticking</strong>: A rapid digital ticking indicating that pedestrians may cross the street. An aid for the visually-impaired.</figcaption>
                    </figure>
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/jealousy.mp3"></audio>
                        <figcaption><strong>Jealousy</strong>: In the words of Ray, "the sound that my stuffed animal whale does when I pressed it on the back. I feel like the sound is a demand for more love and hugs".</figcaption>
                    </figure>
                    <figure>
                        <audio loading="lazy" controls src="https://assets.nasif.co/squishyness.mp3"></audio>
                        <figcaption><strong>Squishiness</strong>: The dreadful sound of a dish soap bottle that has run out.</figcaption>
                    </figure>
                </div>
                <p>We also got started on our project for next week, which will be documented on the week 2 blog post.</p>
            </div>
        </div>
    </main>
    <script src="../../js/pixelBG.js"></script>
</body>
</html>